# MBUA512 Week 9 - Correlation & Regression
# Ported to Slide Framework

meta:
  title: "MBUA512 - Databases and Analytics"
  subtitle: "Week 9: Correlation & Regression"
  authors:
    - "Markus Luczak-Roesch"
    - "Bogdan State"
  date: "2026"

config:
  theme: "default"
  webr:
    enabled: true
    packages:
      - ggplot2
  datasets: {}

# Note: This presentation has many custom interactive slides.
# Those are defined in interactives.js and loaded separately.
# Standard slides are defined here in YAML.

slides:
  # ===== TITLE =====
  - type: title
    title: "MBUA512 – Databases and Analytics"
    subtitle: "Week 9: Correlation & Regression"
    authors: ["Markus Luczak-Roesch", "Bogdan State"]
    background: "https://images.unsplash.com/photo-1462331940025-496dfbfc7564?w=1920&q=80"
    overlay: 0.4
    attribution: "Photo by NASA on Unsplash"

  # ===== MULTIVARIATE ANALYSIS =====
  - type: section
    number: 1
    title: "Multivariate Analysis"

  - type: content
    title: "Multivariate Analysis"
    bullets:
      - "Data with <strong>3 or more variables</strong> collected per observation"
      - "Enables analysis of <strong>relationships between variables</strong>"
      - "Foundation for regression, classification, and prediction"

  # Datasaurus animation - custom interactive
  - type: interactive
    id: datasaurus
    config:
      dataUrl: "assets/correlation_data.json"

  - type: content
    title: "Correlation Basics"
    bullets:
      - "Measures the <strong>strength and direction</strong> of a relationship"
      - "Values range from <strong>-1 to +1</strong>"
      - "Zero means no linear relationship"
      - "<strong>Correlation does not imply causation!</strong>"

  # ===== CLEAR QUESTION =====
  - type: section
    number: 2
    title: "Formulate a Clear Question"

  - type: image
    src: "assets/spurious_correlation.svg"
    alt: "Spurious Correlation Example"

  # ===== IDENTIFY VARIABLES =====
  - type: section
    number: 3
    title: "Identify Two Variables"

  - type: content
    title: "Confusing Question → Confusing Answer"
    bullets:
      - "Be specific about what you're measuring"
      - "Define your variables clearly"
      - "Consider confounding factors"

  # Fun During vs Fun After - two panel image
  - type: interactive
    id: fun-comparison

  # Sample data table
  - type: interactive
    id: sample-data-table

  # ===== RANDOM SAMPLE =====
  - type: section
    number: 4
    title: "Random Sample"

  # ===== GRAPH RESPONSES =====
  - type: section
    number: 5
    title: "Graph Responses"

  # Type 1 vs Type 2 Fun - R code slide
  - type: code
    id: sp-fun
    title: "R Code - Type 1 vs Type 2 Fun"
    preload: |
      # Load fun data
      fun_data <- data.frame(
        Activity = c("Cleaning", "Renovation", "Marathon", "Moving", "Backpacking",
                     "Cooking", "Concert", "Waiting", "Road trip", "Picnic"),
        FunDuring = c(3.6, 4.6, 3.0, 3.0, 3.6, 6.6, 8.4, 4.7, 7.4, 9.4),
        FunAfter = c(5.1, 4.8, 6.5, 6.5, 5.6, 7.0, 8.2, 3.6, 6.8, 10.0)
      )
    code: |
      # Type 1 vs Type 2 Fun Analysis
      library(ggplot2)

      # Scatterplot
      ggplot(fun_data, aes(x = FunDuring, y = FunAfter, color = Activity)) +
        geom_point(size = 4, alpha = 0.8) +
        labs(
          title = "Type 1 vs Type 2 Fun",
          x = "Fun During Activity",
          y = "Fun Remembered After"
        ) +
        theme_minimal(base_size = 16) +
        theme(legend.position = "right")

  # ===== TYPES OF RELATIONSHIPS =====
  - type: section
    number: 6
    title: "Types of Relationships"

  # ===== POSITIVE RELATIONSHIP =====
  - type: section
    title: "Positive Relationship"

  # Fire Incidents - Structures Burned vs Firefighters
  - type: code
    id: sp-fire-structures
    title: "R Code - Structures Burned vs Firefighters"
    preload: |
      # Fire incidents data (synthetic)
      set.seed(42)
      structures_burned <- c(1, 15, 7, 4, 1, 2, 1, 10, 5, 5, 1, 16, 8, 3, 12, 2, 6, 9, 3, 11, 7, 2, 14, 4, 9)
      firefighters <- c(16, 85, 40, 23, 5, 10, 5, 61, 31, 31, 5, 94, 46, 15, 72, 8, 38, 52, 19, 67, 44, 12, 88, 25, 55)
      property_damage <- c(659930, 2805215, 1423669, 1137953, 425734, 378727, 363856, 2135502, 1184497, 1355431, 143651, 3325208, 1938762, 242278, 2456789, 298456, 1345678, 1876543, 567890, 2234567, 1567890, 345678, 2987654, 876543, 1789012)
    code: |
      # Fire Incidents - Structures Burned vs Firefighters
      # Data preloaded: structures_burned, firefighters, property_damage

      par(mar = c(5, 5, 4, 2))
      plot(structures_burned, firefighters,
           pch = 19, cex = 1.2, col = "#3498db88",
           xlab = "Structures Burned",
           ylab = "Number of Firefighters",
           main = "Structures Burned vs Firefighters",
           cex.lab = 1.4, cex.main = 1.6, cex.axis = 1.2)

      # Add trend line
      abline(lm(firefighters ~ structures_burned),
             col = "#2980b9", lwd = 2)

      # Add correlation
      r <- cor(structures_burned, firefighters)
      text(12, 20, paste("r =", round(r, 3)),
           cex = 1.5, col = "#2980b9")

  # Fire Incidents - Property Damage vs Structures Burned
  - type: code
    id: sp-fire-damage
    title: "R Code - Property Damage vs Structures Burned"
    preload: |
      # Fire incidents data (synthetic)
      set.seed(42)
      structures_burned <- c(1, 15, 7, 4, 1, 2, 1, 10, 5, 5, 1, 16, 8, 3, 12, 2, 6, 9, 3, 11, 7, 2, 14, 4, 9)
      firefighters <- c(16, 85, 40, 23, 5, 10, 5, 61, 31, 31, 5, 94, 46, 15, 72, 8, 38, 52, 19, 67, 44, 12, 88, 25, 55)
      property_damage <- c(659930, 2805215, 1423669, 1137953, 425734, 378727, 363856, 2135502, 1184497, 1355431, 143651, 3325208, 1938762, 242278, 2456789, 298456, 1345678, 1876543, 567890, 2234567, 1567890, 345678, 2987654, 876543, 1789012)
    code: |
      # Fire Incidents - Property Damage vs Structures Burned
      # Data preloaded: structures_burned, firefighters, property_damage

      par(mar = c(5, 6, 4, 2))
      plot(structures_burned, property_damage / 1e6,
           pch = 19, cex = 1.2, col = "#9b59b688",
           xlab = "Structures Burned",
           ylab = "Property Damage ($ millions)",
           main = "Property Damage vs Structures Burned",
           cex.lab = 1.4, cex.main = 1.6, cex.axis = 1.2)

      # Add trend line
      abline(lm(property_damage / 1e6 ~ structures_burned),
             col = "#8e44ad", lwd = 2)

      # Add correlation
      r <- cor(structures_burned, property_damage)
      text(12, 1, paste("r =", round(r, 3)),
           cex = 1.5, col = "#8e44ad")

  # Fire incidents code slides
  - type: code
    id: sp-fire1
    title: "R Code - Firefighters vs Property Damage"
    preload: |
      # Fire incidents data (synthetic)
      fire_data <- data.frame(
        firefighters = c(16, 85, 40, 23, 5, 10, 5, 61, 31, 31, 5, 94, 46, 15,
                         72, 8, 38, 52, 19, 67, 44, 12, 88, 25, 55),
        property_damage = c(659930, 2805215, 1423669, 1137953, 425734, 378727,
                           363856, 2135502, 1184497, 1355431, 143651, 3325208,
                           1938762, 242278, 2456789, 298456, 1345678, 1876543,
                           567890, 2234567, 1567890, 345678, 2987654, 876543, 1789012)
      )
    code: |
      # Fire Incidents Analysis
      library(ggplot2)

      ggplot(fire_data, aes(x = firefighters, y = property_damage / 1e6)) +
        geom_point(color = "#e74c3c", size = 3, alpha = 0.7) +
        geom_smooth(method = "lm", se = TRUE, color = "#2c3e50") +
        labs(
          title = "Fire Incidents: Firefighters vs Property Damage",
          x = "Number of Firefighters",
          y = "Property Damage ($ millions)"
        ) +
        theme_minimal(base_size = 16)

  # ===== NEGATIVE RELATIONSHIP =====
  - type: section
    title: "Negative Relationship"

  # Marathon code slides
  - type: code
    id: sp-marathon
    title: "R Code - Marathon Time vs Opinion"
    preload: |
      # Marathon opinion data
      marathon_data <- data.frame(
        time_minutes = c(112, 9, 7, 47, 129, 22, 626, 105, 31, 18,
                        13, 137, 24, 2, 89, 156, 68, 41, 198, 55),
        opinion_score = c(2.2, 6.2, 6.7, 4.8, 3.1, 6.7, 0.9, 3.4, 4.9, 5.4,
                         6.1, 3.5, 6.2, 7.0, 4.2, 2.8, 5.1, 5.8, 1.5, 5.0)
      )
    code: |
      # Marathon Opinion Analysis
      library(ggplot2)

      ggplot(marathon_data, aes(x = time_minutes, y = opinion_score)) +
        geom_point(color = "#3498db", size = 3, alpha = 0.7) +
        geom_smooth(method = "lm", se = TRUE, color = "#e74c3c") +
        labs(
          title = "Marathon: Finish Time vs Opinion of Experience",
          x = "Finish Time (minutes)",
          y = "Opinion Score (1-10)"
        ) +
        theme_minimal(base_size = 16)

  # Marathon Opinion - Log Scale
  - type: code
    id: sp-marathon-log
    title: "R Code - Marathon Opinion (Log Scale)"
    preload: |
      # Marathon opinion data
      set.seed(123)
      meters_run <- c(6736.2, 563.9, 394.0, 2801.2, 7740.9, 1290.5, 37563.1, 6278.5, 1830.5, 1070.1,
                      796.0, 8202.5, 1417.0, 143.4, 1109.1, 8658.3, 301.4, 288.8, 2485.8, 2489.9,
                      4628.8, 16981.7, 7977.8, 4018.8, 7881.4, 704.5, 890.8, 397.4, 590.3, 4534.0,
                      174.5, 1375.9, 1352.5, 1977.2, 1311.9, 660.3, 1316.1, 22150.3, 30106.9, 2077.1,
                      4345.5, 201.2, 680.7, 1227.5, 18805.6, 454.5)
      opinion <- c(2.2, 6.2, 6.7, 4.8, 3.1, 6.7, 0.9, 3.4, 4.9, 5.4, 6.1, 3.5, 6.2, 7.0, 5.2,
                   2.8, 7.8, 7.0, 3.3, 4.7, 3.8, 2.4, 2.4, 5.2, 3.0, 6.0, 5.2, 6.2, 5.5, 3.6,
                   7.2, 6.8, 4.0, 4.1, 5.1, 6.7, 5.1, 2.4, 0.9, 4.9, 5.1, 7.0, 6.5, 5.6, 0.6, 6.2)
    code: |
      # Marathon Opinion - Meters Run vs Opinion (Log Scale)
      # Data preloaded: meters_run, opinion
      # Meters: 100m to 42,195m (full marathon)
      # Opinion: 0 (Never again) to 9 (Best thing ever)

      par(mar = c(5, 5, 4, 2))
      plot(meters_run, opinion,
           pch = 19, cex = 1.2, col = "#c0392b88",
           log = "x",  # Log scale for meters axis
           xlab = "Meters Run During Marathon (log scale)",
           ylab = "Opinion of Running (0-9)",
           main = "Opinion During Marathon (Log Scale)",
           cex.lab = 1.3, cex.main = 1.5, cex.axis = 1.1,
           xaxt = "n", ylim = c(0, 9))

      # Custom x-axis labels
      axis(1, at = c(100, 500, 1000, 5000, 10000, 42195),
           labels = c("100m", "500m", "1km", "5km", "10km", "42km"),
           cex.axis = 1.1)

      # Add trend line (on log scale)
      fit <- lm(opinion ~ log10(meters_run))
      x_seq <- 10^seq(2, 4.63, length.out = 100)
      lines(x_seq, predict(fit, newdata = data.frame(meters_run = x_seq)),
            col = "#c0392b", lwd = 2)

      # Add correlation (log scale)
      r <- cor(log10(meters_run), opinion)
      text(20000, 8, paste("r =", round(r, 3)), cex = 1.4, col = "#c0392b")

  # ===== NO/WEAK RELATIONSHIP =====
  - type: section
    title: "No (Weak) Relationship"
    background: "https://images.unsplash.com/photo-1504280390367-361c6d9f38f4?w=1920&q=80"
    attribution: "Photo by Rahul Chowdhury on Unsplash"

  # Beer price vs evaluation
  - type: code
    id: sp-beer1
    title: "R Code - Beer Price vs Overall Evaluation"
    preload: |
      # Belgian beer data (229 beers)
      set.seed(42)
      n <- 229
      avg_price <- c(runif(180, 1, 30), runif(30, 30, 60), runif(19, 60, 90))
      overall <- rnorm(n, 0, 0.5) + 0.005 * avg_price
    code: |
      # Beer Price vs Overall Evaluation
      # Data preloaded: avg_price, overall
      # 229 Belgian beers with price and tasting data

      par(mar = c(5, 5, 4, 2))
      plot(avg_price, overall,
           pch = 19, cex = 1.2, col = "#7f8c8d88",
           xlab = "Average Price (EUR)",
           ylab = "Overall Evaluation (standardized)",
           main = "Beer Price vs Expert Evaluation",
           cex.lab = 1.3, cex.main = 1.5, cex.axis = 1.1)

      # Add trend line
      fit <- lm(overall ~ avg_price)
      abline(fit, col = "#7f8c8d", lwd = 2)

      # Add correlation
      r <- cor(avg_price, overall)
      text(50, 1, paste("r =", round(r, 3)), cex = 1.4, col = "#7f8c8d")

  # Beer - identifying influential points
  - type: code
    id: sp-beer2
    title: "R Code - Identifying Influential Points"
    preload: |
      # Belgian beer data (229 beers)
      set.seed(42)
      n <- 229
      avg_price <- c(runif(180, 1, 30), runif(30, 30, 60), runif(19, 60, 90))
      overall <- rnorm(n, 0, 0.5) + 0.005 * avg_price
    code: |
      # Identifying Influential Points (DFBETA)
      # Data preloaded: avg_price, overall

      # Fit regression and calculate DFBETA
      fit <- lm(overall ~ avg_price)
      dfb <- dfbeta(fit)[, 2]  # DFBETA for slope

      # Find 25 most influential points (highest |dfbeta|)
      influential <- order(abs(dfb), decreasing = TRUE)[1:25]

      par(mar = c(5, 5, 4, 2))
      plot(avg_price, overall,
           pch = 19, cex = 1.2, col = "#7f8c8d88",
           xlab = "Average Price (EUR)",
           ylab = "Overall Evaluation (standardized)",
           main = "Identifying 25 Most Influential Points",
           cex.lab = 1.3, cex.main = 1.5, cex.axis = 1.1)

      # Highlight the 25 most influential points
      points(avg_price[influential], overall[influential],
             pch = 19, cex = 1.5, col = "#e74c3c")

      # Add trend line
      abline(fit, col = "#7f8c8d", lwd = 2)

      # Add correlation
      r <- cor(avg_price, overall)
      text(50, 1, paste("r =", round(r, 3)), cex = 1.4, col = "#7f8c8d")

      # Legend
      legend("bottomright", "25 highest |DFBETA|",
             pch = 19, col = "#e74c3c", cex = 1.1)

  # Beer - After Removing Influential Points
  - type: code
    id: sp-beer3
    title: "R Code - After Removing Influential Points"
    preload: |
      # Belgian beer data (229 beers)
      set.seed(42)
      n <- 229
      avg_price <- c(runif(180, 1, 30), runif(30, 30, 60), runif(19, 60, 90))
      overall <- rnorm(n, 0, 0.5) + 0.005 * avg_price
    code: |
      # After Removing 25 Influential Points
      # Data preloaded: avg_price, overall

      # Fit regression and calculate DFBETA
      fit <- lm(overall ~ avg_price)
      dfb <- dfbeta(fit)[, 2]  # DFBETA for slope

      # Find 25 most influential points (highest |dfbeta|)
      influential <- order(abs(dfb), decreasing = TRUE)[1:25]

      # Remove influential points
      price_clean <- avg_price[-influential]
      overall_clean <- overall[-influential]

      par(mar = c(5, 5, 4, 2))
      plot(price_clean, overall_clean,
           pch = 19, cex = 1.2, col = "#27ae6088",
           xlab = "Average Price (EUR)",
           ylab = "Overall Evaluation (standardized)",
           main = "After Removing 25 Influential Points",
           cex.lab = 1.3, cex.main = 1.5, cex.axis = 1.1)

      # Add trend line
      fit_clean <- lm(overall_clean ~ price_clean)
      abline(fit_clean, col = "#27ae60", lwd = 2)

      # Add correlation
      r_clean <- cor(price_clean, overall_clean)
      text(35, 0.8, paste("r =", round(r_clean, 3)), cex = 1.4, col = "#27ae60")

      # Show comparison
      r_orig <- cor(avg_price, overall)
      text(35, 0.5, paste("(was", round(r_orig, 3), "with all data)"),
           cex = 1.1, col = "#7f8c8d")

  # Hotel data - variance affects correlation
  - type: code
    id: sp-hotel
    title: "R Code - Hotel Fun by Humidity Level"
    preload: |
      # Hotel data: Fun vs Price, Split by Humidity
      set.seed(123)
      n <- 100
      hotel_cost <- runif(n, 50, 500)
      humidity <- runif(n, 30, 90)
      fun_reported <- 3 + 0.01 * hotel_cost + ifelse(humidity < 60, rnorm(n, 0, 2), rnorm(n, 0, 0.8))
      fun_reported <- pmax(1, pmin(10, fun_reported))
    code: |
      # Hotel Data: Fun vs Price, Split by Humidity
      # Data preloaded: hotel_cost, fun_reported, humidity

      # Split by humidity threshold
      low_humid <- humidity < 60
      high_humid <- humidity >= 60

      # Set up 2-panel layout
      par(mfrow = c(1, 2), mar = c(5, 5, 4, 2))

      # Left panel: Low humidity (high variance)
      plot(hotel_cost[low_humid], fun_reported[low_humid],
           pch = 19, cex = 1.2, col = "#3498db88",
           xlab = "Hotel Cost (USD/night)",
           ylab = "Fun Reported (1-10)",
           main = "Low Humidity (<60%)",
           xlim = c(50, 500), ylim = c(1, 10),
           cex.lab = 1.3, cex.main = 1.5, cex.axis = 1.1)
      r_low <- cor(hotel_cost[low_humid], fun_reported[low_humid])
      text(400, 2, paste("r =", round(r_low, 3)), cex = 1.4, col = "#2980b9")

      # Right panel: High humidity (low variance)
      plot(hotel_cost[high_humid], fun_reported[high_humid],
           pch = 19, cex = 1.2, col = "#e74c3c88",
           xlab = "Hotel Cost (USD/night)",
           ylab = "Fun Reported (1-10)",
           main = "High Humidity (>=60%)",
           xlim = c(50, 500), ylim = c(1, 10),
           cex.lab = 1.3, cex.main = 1.5, cex.axis = 1.1)
      r_high <- cor(hotel_cost[high_humid], fun_reported[high_humid])
      text(400, 2, paste("r =", round(r_high, 3)), cex = 1.4, col = "#c0392b")

  # ===== CORRELATION =====
  - type: section
    number: 7
    title: "Correlation"

  - type: content
    title: "What is the correlation coefficient ρ?"
    bullets:
      - "Does a relationship exist?"
      - "If so, is it positive or negative?"
      - "Is it strong or weak?"

  # Correlation formula
  - type: content
    title: "Correlation Coefficient Formula"
    bullets:
      - "<strong>Pearson's r</strong> (population ρ, sample r)"
      - "r = Σ[(xᵢ - x̄)(yᵢ - ȳ)] / √[Σ(xᵢ - x̄)² × Σ(yᵢ - ȳ)²]"
      - "Measures <em>linear</em> association only"
      - "Unitless: works regardless of measurement scale"

  # Interactive rho slider - custom
  - type: interactive
    id: rho-slider

  # R-squared Venn diagram - custom
  - type: interactive
    id: r2-venn

  - type: content
    title: "Interpreting Correlation Strength"
    bullets:
      - "<strong>|r| > 0.7</strong>: Strong relationship"
      - "<strong>0.4 < |r| < 0.7</strong>: Moderate relationship"
      - "<strong>|r| < 0.4</strong>: Weak relationship"
      - "Sign indicates direction: positive (+) or negative (−)"

  # Interpreting Correlation Coefficients section
  - type: section
    title: "Interpreting Correlation Coefficients"

  # Large vs Small Coefficients
  - type: interactive
    id: large-vs-small-coefficients

  # Zero vs Perfect Correlation
  - type: interactive
    id: zero-vs-perfect

  # Single Summary Number
  - type: interactive
    id: single-summary-number

  # ρ is not percent, R² is
  - type: interactive
    id: rho-not-percent

  # Large R² means better predictions
  - type: interactive
    id: large-r2-better

  - type: content
    title: "ρ vs R² — What's the Difference?"
    bullets:
      - "ρ = 0.90 <strong>≠</strong> 90% of variance explained"
      - "The correlation coefficient is a <em>ratio</em>, not a percent"
      - "R² = ρ² = proportion of variance explained"
      - "Example: ρ = 0.7 → R² = 0.49 (only 49% explained!)"

  - type: content
    title: "When to Use Correlation"
    bullets:
      - "Both variables must be <strong>interval or ratio scale</strong>"
      - "Correlation measures <em>linear</em> relationships only"
      - "Use for continuous numerical data"
      - "Not appropriate for categorical or ordinal data"

  # ===== REGRESSION =====
  - type: section
    number: 8
    title: "Regression Analysis"

  - type: quote
    text: "Linear regression is a method that summarizes how the average values of a numerical outcome variable vary over subpopulations defined by linear functions of predictors."
    author: "Gelman & Hill"

  - type: content
    title: "Use Regression For"
    bullets:
      - "<strong>Description:</strong> Summarize relationships in data"
      - "<strong>Prediction:</strong> Estimate outcomes for new observations"
      - "<strong>Causal inference:</strong> (with appropriate design)"

  # Regression examples
  - type: content
    title: "Regression Example: Predicting Height"
    bullets:
      - "<strong>Question:</strong> Can we predict a child's height?"
      - "<strong>Variables:</strong> Mother's height, Father's height → Child's height"
      - "<strong>Method:</strong> Linear regression"
      - "<strong>Use case:</strong> Understanding genetic inheritance"

  - type: content
    title: "Regression Example: Crop Yield"
    bullets:
      - "<strong>Question:</strong> What affects crop yield?"
      - "<strong>Variables:</strong> Rainfall, Fertilizer, Temperature → Yield"
      - "<strong>Method:</strong> Multiple regression"
      - "<strong>Use case:</strong> Agricultural optimization"

  - type: content
    title: "Regression Example: Income Prediction"
    bullets:
      - "<strong>Question:</strong> What predicts income?"
      - "<strong>Variables:</strong> Education level, Years of experience → Income"
      - "<strong>Method:</strong> Linear regression"
      - "<strong>Use case:</strong> Labor economics, career planning"

  # Simple regression formula
  - type: content
    title: "Simple Linear Regression"
    bullets:
      - "Y = β₀ + β₁X + ε"
      - "β₀ = intercept (value when X = 0)"
      - "β₁ = slope (change in Y per unit change in X)"
      - "ε = error term"

  # Multiple regression
  - type: content
    title: "Multiple Regression"
    bullets:
      - "Y = β₀ + β₁X₁ + β₂X₂ + ... + βₖXₖ + ε"
      - "Controls for multiple variables simultaneously"
      - "Each coefficient shows effect holding others constant"

  # Fitted values and residuals
  - type: content
    title: "Fitted Values and Residuals"
    bullets:
      - "<strong>Fitted value</strong>: ŷᵢ = β₀ + β₁xᵢ (predicted)"
      - "<strong>Residual</strong>: eᵢ = yᵢ − ŷᵢ (observed − predicted)"
      - "Residuals measure prediction error"
      - "Sum of residuals = 0 (by design)"

  # Regression code slide
  - type: code
    id: sp-regression
    title: "R Code - Linear Regression"
    code: |
      # Simple Linear Regression
      library(ggplot2)

      # Fit model
      model <- lm(mpg ~ wt, data = mtcars)
      summary(model)

      # Visualize
      ggplot(mtcars, aes(x = wt, y = mpg)) +
        geom_point(size = 3) +
        geom_smooth(method = "lm", se = TRUE) +
        labs(
          title = "MPG vs Weight",
          x = "Weight (1000 lbs)",
          y = "Miles per Gallon"
        ) +
        theme_minimal()

  # Pima Diabetes example
  - type: code
    id: sp-pima-diabetes
    title: "R Code - Pima Indians Diabetes"
    preload: |
      # Load Pima Indians Diabetes Dataset
      # Features: glucose, BMI, age, etc.
      # Outcome: diabetes (0 = no, 1 = yes)
      library(mlbench)
      data(PimaIndiansDiabetes)
      pima <- PimaIndiansDiabetes
    code: |
      # Logistic Regression - Pima Indians Diabetes
      library(mlbench)
      data(PimaIndiansDiabetes)

      # Fit logistic regression model
      model <- glm(diabetes ~ glucose + mass + age,
                   data = PimaIndiansDiabetes,
                   family = binomial)

      # Show summary
      summary(model)

      # Note: This is logistic regression (binary outcome)
      # Coefficients are log-odds ratios

  # ===== MODEL FITTING =====
  - type: section
    title: "Model Fitting"

  # Least squares animation - custom
  - type: interactive
    id: least-squares

  # SSR visualization - squared residuals
  - type: interactive
    id: ssr-visualization

  # STONKS slide - custom
  - type: interactive
    id: stonks

  # R² explanation
  - type: content
    title: "Understanding R²"
    bullets:
      - "<strong>Total Sum of Squares (TSS)</strong>: Σ(yᵢ − ȳ)² — total variance"
      - "<strong>Residual Sum of Squares (RSS)</strong>: Σ(yᵢ − ŷᵢ)² — unexplained variance"
      - "<strong>R² = 1 − (RSS/TSS)</strong> = proportion explained"
      - "R² = 0.8 means 80% of variance is explained by the model"

  # Adjusted R²
  - type: content
    title: "Adjusted R²"
    bullets:
      - "Penalizes adding unnecessary predictors"
      - "Adj. R² = 1 − [(1 − R²)(n − 1) / (n − p − 1)]"
      - "Use when comparing models with different numbers of predictors"

  # ===== ASSUMPTIONS =====
  - type: section
    title: "Regression Assumptions"

  - type: content
    title: "Key Assumptions for Valid Inference"
    bullets:
      - "<strong>Linearity</strong>: Relationship is approximately linear"
      - "<strong>Independence</strong>: Observations are independent"
      - "<strong>Normality</strong>: Residuals are normally distributed"
      - "<strong>Homoscedasticity</strong>: Constant variance of residuals"

  # Normal distribution 3D visualization
  - type: interactive
    id: normal-distribution

  # Linear relationship visualization
  - type: interactive
    id: linear-relationship

  # Homoscedasticity visualization
  - type: interactive
    id: homoscedasticity

  - type: content
    title: "What Happens When Assumptions Fail?"
    bullets:
      - "Non-linearity → biased predictions, poor fit"
      - "Non-independence → underestimated standard errors"
      - "Non-normality → unreliable confidence intervals"
      - "Heteroscedasticity → inefficient estimates"

  # ===== CAUSATION =====
  - type: section
    number: 9
    title: "Causation"

  - type: content
    title: "Prediction ≠ Causation"
    bullets:
      - "Correlation shows association, not cause"
      - "Confounding variables can create spurious correlations"
      - "Experimental design needed for causal claims"

  # Chocolate consumption slide - R code with WebR
  - type: code
    id: sp-chocolate
    title: "R Code - Nobel Laureates vs Chocolate Consumption"
    code: |
      # Data from kustats::ds16_Nobel_Laureates_and_Chocolate
      # Source: Messerli (2012) NEJM; Triola (2018) Elementary Statistics

      data <- data.frame(
        Country = c("Australia", "Austria", "Belgium", "Brazil", "Canada", "China",
                    "Denmark", "Finland", "France", "Germany", "Greece", "Ireland",
                    "Italy", "Japan", "Netherlands", "Norway", "Poland", "Portugal",
                    "Spain", "Sweden", "Switzerland", "United Kingdom", "United States"),
        CHOCOLATE = c(4.8, 8.5, 5.7, 2.9, 3.9, 0.7, 8.5, 7.3, 6.3, 11.6, 2.5, 9.0,
                      3.7, 2.0, 4.5, 9.4, 3.2, 2.0, 3.6, 6.4, 11.9, 9.7, 5.3),
        NOBEL = c(5.2, 24.7, 8.7, 0.1, 6.0, 0.1, 25.3, 7.6, 9.0, 12.8, 1.5, 12.7,
                  3.3, 1.3, 8.0, 23.4, 3.1, 1.4, 1.8, 31.0, 31.5, 18.9, 10.5)
      )

      library(ggplot2)

      ggplot(data, aes(x = CHOCOLATE, y = NOBEL)) +
        geom_point(size = 4, alpha = 0.7, color = "#8B4513") +
        geom_smooth(method = "lm", se = TRUE, color = "#D2691E") +
        labs(
          title = "Nobel Laureates vs Chocolate Consumption",
          x = "Chocolate Consumption (kg/capita/year)",
          y = "Nobel Laureates per 10M Population",
          caption = "Messerli (2012) NEJM"
        ) +
        theme_minimal(base_size = 16) +
        theme(
          plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
          plot.caption = element_text(size = 10, hjust = 0.5, color = "gray30")
        )

  # ===== CONCLUSION =====
  - type: section
    title: "Summary"

  - type: content
    title: "Key Takeaways"
    bullets:
      - "Correlation measures linear relationship strength (-1 to +1)"
      - "R² shows proportion of variance explained"
      - "Regression models relationships and enables prediction"
      - "Always consider: Correlation ≠ Causation"

  # Final R code example - summary statistics
  - type: code
    id: sp-summary
    title: "R Code - Complete Regression Analysis"
    preload: |
      # Using built-in mtcars dataset
    code: |
      # Complete regression example with mtcars
      library(ggplot2)

      # Fit model
      model <- lm(mpg ~ wt + hp, data = mtcars)

      # Show summary
      summary(model)

  # Annotated summary output - interactive
  - type: interactive
    id: annotated-summary

  # ===== MODEL EVALUATION =====
  - type: section
    title: "Model Evaluation"

  # Confusion matrix metrics - interactive
  - type: interactive
    id: confusion-matrix

  # Chihuahua detector example
  - type: interactive
    id: chihuahua-detector

  - type: content
    title: "Choosing the Right Metric"
    bullets:
      - "<strong>Accuracy</strong>: Good for balanced datasets"
      - "<strong>Precision</strong>: When false positives are costly (spam filter)"
      - "<strong>Recall</strong>: When false negatives are costly (disease detection)"
      - "<strong>F1 Score</strong>: Balance between precision and recall"
